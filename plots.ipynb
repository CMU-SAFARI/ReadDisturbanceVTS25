{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"./data\"):\n",
    "  for file in files:\n",
    "    if \"rd_hcf.csv\" in file and \"mimi\" not in file:\n",
    "      module = file.split(\"_\")[0]\n",
    "      df = pd.read_csv(os.path.join(root, file))\n",
    "      df[\"module\"] = module\n",
    "      # print(df[\"Itr\"].unique())\n",
    "      dfs.append(df)\n",
    "      \n",
    "\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "display(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out SA edge victims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in df[\"module\"].unique():\n",
    "  module_data = df.loc[(df[\"module\"] == module) & (df[\"Aggr. Type\"].isin([\"Upper\", \"Lower\"]))]\n",
    "  type_counts = module_data.groupby('Vic Row')['Aggr. Type'].nunique()\n",
    "  incomplete_idx = type_counts[type_counts == 1].index\n",
    "  incomplete_rows = module_data[module_data['Vic Row'].isin(incomplete_idx)][\"Vic Row\"].unique()\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_patterns(df, rows_to_swap):\n",
    "  df_copy = df.copy()\n",
    "  \n",
    "  # Create a mask for the rows we want to modify\n",
    "  mask = df_copy['Vic Row'].isin(rows_to_swap)\n",
    "  \n",
    "  df_copy.loc[mask & (df_copy['Data Pattern'] == '0x00000000'), 'Data Pattern'] = '_0xFFFFFFFF'\n",
    "  df_copy.loc[mask & (df_copy['Data Pattern'] == '0xFFFFFFFF'), 'Data Pattern'] = '_0x00000000'\n",
    "\n",
    "  df_copy.loc[mask & (df_copy['Data Pattern'] == '_0x00000000'), 'Data Pattern'] = '0x00000000'\n",
    "  df_copy.loc[mask & (df_copy['Data Pattern'] == '_0xFFFFFFFF'), 'Data Pattern'] = '0xFFFFFFFF'\n",
    "\n",
    "  return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_mapping = {\n",
    "  \"axmicr02\"  : \"Mfr. M 8Gb E-Die\",\n",
    "  \"hisasa00\"  : \"Mfr. S 8Gb B-Die\",        \n",
    "  \"sasa05\"    : \"Mfr. S 8Gb D-Die\",      \n",
    "  \"hisasa01\"  : \"Mfr. S 8Gb E-Die\",      \n",
    "  \"hisasa02\"  : \"Mfr. S 16Gb M-Die\",          \n",
    "  \"hisasa03\"  : \"Mfr. S 16Gb A-Die\",        \n",
    "  \"sasa23\"    : \"Mfr. S 16Gb B-Die\",\n",
    "  \"sasa29\"    : \"Mfr. S 16Gb C-Die\",      \n",
    "  \"hyhy0c\"    : \"Mfr. H 8Gb C-Die\",        \n",
    "  \"hyhy13\"    : \"Mfr. H 8Gb D-Die\",      \n",
    "  \"hyhy1e\"    : \"Mfr. H 16Gb A-Die\",    \n",
    "  \"hyhy03\"    : \"Mfr. H 16Gb C-Die\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    '0x00000000': '0 →1 ',\n",
    "    '0xFFFFFFFF': '1 → 0',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_palette = ['#2ecc71',    # green\n",
    "                  '#3498db',    # blue\n",
    "]\n",
    "\n",
    "label_color_map = {\n",
    "    \"S\" : \"#e74c3c\",\n",
    "    \"H\" : \"#9b59b6\",\n",
    "    \"M\" : \"#e67e22\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.loc[df[\"Aggr. Type\"] == \"Double\"]\n",
    "modules = df['module'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set maximum display rows\n",
    "pd.set_option('display.max_rows', 100)  # Change number as needed\n",
    "\n",
    "# Set maximum display columns\n",
    "pd.set_option('display.max_columns', 20)  # Change number as needed\n",
    "\n",
    "# Set width of the display in characters\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Set maximum column width\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np\n",
    "def format_k(x, p):\n",
    "  return f'{int(x/1000)}K' if x >= 1000 else str(int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.loc[df[\"Aggr. Type\"] == \"Double\"]\n",
    "modules = df['module'].unique()\n",
    "\n",
    "# Calculate grid dimensions\n",
    "n_cols = 4  # You can adjust this\n",
    "n_rows = (len(modules) + n_cols - 1) // n_cols\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 2*n_rows))\n",
    "# _axes = axes\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes\n",
    "# plt.subplots_adjust(hspace=0.7)\n",
    "\n",
    "avg_dfs = []\n",
    "\n",
    "# Create boxplot for each group\n",
    "for idx, module in enumerate(list(module_mapping.keys())):\n",
    "    # Filter edge victims\n",
    "    ss_data = df[(df['module'] == module) & (df[\"Aggr. Type\"].isin([\"Upper\", \"Lower\"]))]\n",
    "    type_counts = ss_data.groupby('Vic Row')['Aggr. Type'].nunique()\n",
    "    incomplete_idx = type_counts[type_counts == 1].index\n",
    "    incomplete_rows = ss_data[ss_data['Vic Row'].isin(incomplete_idx)][\"Vic Row\"].unique()\n",
    "\n",
    "    group_data = df.loc[(df['module'] == module) & (df[\"Aggr. Type\"] == \"Double\")]\n",
    "    group_data = group_data[~(group_data['Vic Row'].isin(incomplete_rows))]\n",
    "\n",
    "    # Handle Micron true- anti-\n",
    "    if module == \"axmicr02\":\n",
    "      ret_df = pd.read_csv(\"./data/axmicr02_retention.csv\")\n",
    "      ret_df = ret_df.loc[ret_df[\"tWAIT\"] == 4096]\n",
    "\n",
    "      anti_df = ret_df.loc[(ret_df[\"Pattern\"] == \"00000000\") & (ret_df[\"NumBitflips\"] >= 10)]\n",
    "      true_df = ret_df.loc[(ret_df[\"Pattern\"] == \"FFFFFFFF\") & (ret_df[\"NumBitflips\"] >= 10)]\n",
    "\n",
    "      anti_rows = anti_df[\"Row\"].unique() + 1024\n",
    "      true_rows = true_df[\"Row\"].unique() + 1024\n",
    "\n",
    "      group_data = swap_patterns(group_data, list(anti_rows))\n",
    "\n",
    "    adf = group_data.groupby(['Data Pattern'])['HC'].mean().reset_index()\n",
    "    adf[\"module\"] = module\n",
    "    avg_dfs.append(adf)\n",
    "\n",
    "    # Create boxplot on the corresponding subplot\n",
    "    sns.boxplot(data=group_data, x=\"Data Pattern\", y=\"HC\" , ax=axes[idx], order=['0x00000000', '0xFFFFFFFF'], palette=default_palette)\n",
    "\n",
    "    mfr = module_mapping[module].split()[1]\n",
    "    if idx not in [0, 1, 8]:\n",
    "      axes[idx].set_title(f'{\" \".join(module_mapping[module].split()[2:])}', weight='bold', color=label_color_map[mfr])\n",
    "    else:\n",
    "      axes[idx].set_title(f'{module_mapping[module]}', weight='bold', color=label_color_map[mfr])\n",
    "    axes[idx].yaxis.set_major_formatter(FuncFormatter(format_k))\n",
    "    axes[idx].set_xlabel('')\n",
    "    axes[idx].set_ylabel('')\n",
    "    if idx % 4 == 0:\n",
    "      axes[idx].set_ylabel(r'$\\text{HC}_{\\text{First}}$')\n",
    "\n",
    "    y_min, y_max = axes[idx].get_ylim()\n",
    "    margin = (y_max - y_min) * 0.05  # 5% margin\n",
    "    axes[idx].set_ylim(y_min - margin, y_max + margin)\n",
    "    axes[idx].set_yticks(np.linspace(y_min, y_max, 5, endpoint=True))\n",
    "\n",
    "\n",
    "    # Make borders thicker\n",
    "    for spine in axes[idx].spines.values():\n",
    "        spine.set_linewidth(1.6)  # Adjust this number to control thickness\n",
    "        spine.set_color('black')\n",
    "    # Get current x-tick labels\n",
    "    current_labels = [label.get_text() for label in axes[idx].get_xticklabels()]\n",
    "    \n",
    "    # Replace labels using the mapping\n",
    "    new_labels = [label_map.get(label, label) for label in current_labels]\n",
    "    \n",
    "    # Set new labels\n",
    "    axes[idx].set_xticklabels(new_labels, weight='bold')\n",
    "\n",
    "# Remove empty subplots if any\n",
    "for idx in range(len(modules), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "for ax in axes:\n",
    "  ax.grid(True, axis='y', linestyle='--', linewidth=1.0)\n",
    "  ax.tick_params(axis='y', width=1.5, direction='in', color='black')\n",
    "\n",
    "# # fig.supxlabel('Bitfip Direction')\n",
    "# import matplotlib.patches as mpatches\n",
    "# patch1 = mpatches.Patch(color=\"#e74c3c\",  label='Mfr. S')\n",
    "# patch2 = mpatches.Patch(color=\"#9b59b6\",  label='Mfr. H')\n",
    "# patch3 = mpatches.Patch(color=\"#e67e22\",  label='Mfr. M')\n",
    "\n",
    "# # Add a legend at the top center of the figure spanning across columns (ncol=3)\n",
    "# fig.legend(handles=[patch1, patch2, patch3],\n",
    "#            loc='upper center', \n",
    "#            ncol=3,\n",
    "#            bbox_to_anchor=(0.5, 1.05))  # Adjust the y-value to position above the figure\n",
    "\n",
    "# legend = ax.legend(handlelength=0, handletextpad=1,\n",
    "#                    loc='upper center', ncol=3, bbox_to_anchor=(0.5, 1.05))\n",
    "\n",
    "# for text, color in zip(legend.get_texts(), [\"#e74c3c\", \"#9b59b6\", \"#e67e22\"]):\n",
    "#   text.set_color(color)\n",
    "# # plt.show()\n",
    "\n",
    "plt.tight_layout(h_pad=1.3, w_pad=1.2)\n",
    "import matplotlib.lines as mlines\n",
    "# Retrieve each subplot's position (in figure coordinates)\n",
    "positions = []\n",
    "for i, ax in enumerate(axes):\n",
    "  if i % 4 == 0:\n",
    "     positions.append(ax.get_position())\n",
    "# Loop through consecutive rows to compute and draw the dashed line between them\n",
    "for i in range(len(positions) - 1):\n",
    "  # Compute the y position: average between the bottom of the upper subplot\n",
    "  # and the top of the lower subplot\n",
    "  y = (positions[i].y0 + positions[i+1].y1) / 2\n",
    "  # Create a horizontal dashed line across the figure\n",
    "  x = [0, 1] if i != 0 else [0, 0.271]\n",
    "  line = mlines.Line2D(x, [y, y],\n",
    "                        color='black', linestyle='--', linewidth=1,\n",
    "                        transform=fig.transFigure)\n",
    "  fig.add_artist(line)\n",
    "\n",
    "pos = axes[0].get_position()\n",
    "print(pos)\n",
    "print(axes[1].get_position())\n",
    "line = mlines.Line2D([0.271, 0.271], [1, (positions[0].y0 + positions[1].y1) / 2],\n",
    "                     color='black', linestyle='--', linewidth=1,\n",
    "                     transform=fig.transFigure)\n",
    "fig.add_artist(line)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"DS_HCF.png\", pad_inches=0.05)\n",
    "fig.savefig(\"DS_HCF.pdf\", pad_inches=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = pd.concat(avg_dfs)\n",
    "avg_df.columns\n",
    "\n",
    "# Split into two dataframes\n",
    "df_00 = avg_df[avg_df['Data Pattern'] == '0x00000000'][['module', 'HC']].rename(columns={'HC': 'HC_00'})\n",
    "df_FF = avg_df[avg_df['Data Pattern'] == '0xFFFFFFFF'][['module', 'HC']].rename(columns={'HC': 'HC_FF'})\n",
    "\n",
    "# Merge and calculate normalized values\n",
    "result = df_FF.merge(df_00, on='module')\n",
    "result['normalized_HC'] = result['HC_00'] / result['HC_FF']\n",
    "result['diff'] = 1 - result['normalized_HC']\n",
    "result['diff'] = result['diff'].apply(lambda x: f\"{x:.1%}\")\n",
    "\n",
    "geometric_mean = np.exp(np.log(result['normalized_HC']).mean())\n",
    "print(geometric_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"./data\"):\n",
    "  for file in files:\n",
    "    if \"rd_ber.csv\" in file and \"mimi\" not in file:\n",
    "      module = file.split(\"_\")[0]\n",
    "      df = pd.read_csv(os.path.join(root, file))\n",
    "      df[\"module\"] = module\n",
    "      dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"./data\"):\n",
    "  for file in files:\n",
    "    if \"rd_hcf.csv\" in file and \"mimi\" not in file:\n",
    "      module = file.split(\"_\")[0]\n",
    "      _df = pd.read_csv(os.path.join(root, file))\n",
    "      _df[\"module\"] = module\n",
    "      dfs.append(_df)\n",
    "\n",
    "hcf_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.loc[df[\"Aggr. Type\"] == \"Double\"]\n",
    "modules = df['module'].unique()\n",
    "\n",
    "# Calculate grid dimensions\n",
    "n_cols = 4  # You can adjust this\n",
    "n_rows = (len(modules) + n_cols - 1) // n_cols\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 2*n_rows))\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes\n",
    "\n",
    "\n",
    "avg_dfs = []\n",
    "\n",
    "# Create boxplot for each group\n",
    "for idx, module in enumerate(list(module_mapping.keys())):\n",
    "    # Filter edge victims\n",
    "    ss_data = hcf_df[(hcf_df['module'] == module) & (hcf_df[\"Aggr. Type\"].isin([\"Upper\", \"Lower\"]))]\n",
    "    type_counts = ss_data.groupby('Vic Row')['Aggr. Type'].nunique()\n",
    "    incomplete_idx = type_counts[type_counts == 1].index\n",
    "    incomplete_rows = ss_data[ss_data['Vic Row'].isin(incomplete_idx)][\"Vic Row\"].unique()\n",
    "\n",
    "    group_data = df.loc[(df['module'] == module) & (df[\"Aggr. Type\"] == \"Double\")]\n",
    "    group_data = group_data[~(group_data['Vic Row'].isin(incomplete_rows))]\n",
    "\n",
    "\n",
    "\n",
    "    # Handle Micron true- anti-\n",
    "    if module == \"axmicr02\":\n",
    "      ret_df = pd.read_csv(\"./data/axmicr02_retention.csv\")\n",
    "      ret_df = ret_df.loc[ret_df[\"tWAIT\"] == 4096]\n",
    "\n",
    "      anti_df = ret_df.loc[(ret_df[\"Pattern\"] == \"00000000\") & (ret_df[\"NumBitflips\"] >= 10)]\n",
    "      true_df = ret_df.loc[(ret_df[\"Pattern\"] == \"FFFFFFFF\") & (ret_df[\"NumBitflips\"] >= 10)]\n",
    "\n",
    "      anti_rows = anti_df[\"Row\"].unique() + 1024\n",
    "      true_rows = true_df[\"Row\"].unique() + 1024\n",
    "      group_data = swap_patterns(group_data, list(anti_rows))\n",
    "\n",
    "    adf = group_data.groupby(['Data Pattern'])['Num. Bitflips'].mean().reset_index()\n",
    "    adf[\"module\"] = module\n",
    "    avg_dfs.append(adf)\n",
    "\n",
    "\n",
    "    # Create boxplot on the corresponding subplot\n",
    "    sns.boxplot(data=group_data, x=\"Data Pattern\", y=\"Num. Bitflips\" , ax=axes[idx], order=['0x00000000', '0xFFFFFFFF'], palette=default_palette)\n",
    "    mfr = module_mapping[module].split()[1]\n",
    "    if idx not in [0, 1, 8]:\n",
    "      axes[idx].set_title(f'{\" \".join(module_mapping[module].split()[2:])}', weight='bold', color=label_color_map[mfr])\n",
    "    else:\n",
    "      axes[idx].set_title(f'{module_mapping[module]}', weight='bold', color=label_color_map[mfr])\n",
    "    axes[idx].yaxis.set_major_formatter(FuncFormatter(format_k))\n",
    "    axes[idx].set_xlabel('')\n",
    "    axes[idx].set_ylabel('')\n",
    "    if idx % 4 == 0:\n",
    "       axes[idx].set_ylabel(r'Number of Bitflips')\n",
    "\n",
    "    y_min, y_max = axes[idx].get_ylim()\n",
    "    margin = (y_max - y_min) * 0.05  # 5% margin\n",
    "    axes[idx].set_ylim(max(y_min - margin, 0), y_max + margin)\n",
    "    axes[idx].set_yticks(np.linspace(y_min, y_max, 5, endpoint=True))\n",
    "\n",
    "\n",
    "    # Make borders thicker\n",
    "    for spine in axes[idx].spines.values():\n",
    "        spine.set_linewidth(1.6)  # Adjust this number to control thickness\n",
    "        spine.set_color('black')\n",
    "    # Get current x-tick labels\n",
    "    current_labels = [label.get_text() for label in axes[idx].get_xticklabels()]\n",
    "    \n",
    "    # Replace labels using the mapping\n",
    "    new_labels = [label_map.get(label, label) for label in current_labels]\n",
    "    \n",
    "    # Set new labels\n",
    "    axes[idx].set_xticklabels(new_labels, weight=\"bold\")\n",
    "\n",
    "# Remove empty subplots if any\n",
    "for idx in range(len(modules), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "for ax in axes:\n",
    "  ax.grid(True, axis='y', linestyle='--', linewidth=1.0)\n",
    "  ax.tick_params(axis='y', width=1, direction='in', color='black')\n",
    "\n",
    "plt.tight_layout(h_pad=1.3, w_pad=1.2)\n",
    "import matplotlib.lines as mlines\n",
    "# Retrieve each subplot's position (in figure coordinates)\n",
    "positions = []\n",
    "for i, ax in enumerate(axes):\n",
    "  if i % 4 == 0:\n",
    "     positions.append(ax.get_position())\n",
    "# Loop through consecutive rows to compute and draw the dashed line between them\n",
    "for i in range(len(positions) - 1):\n",
    "  # Compute the y position: average between the bottom of the upper subplot\n",
    "  # and the top of the lower subplot\n",
    "  y = (positions[i].y0 + positions[i+1].y1) / 2\n",
    "  # Create a horizontal dashed line across the figure\n",
    "  x = [0, 1] if i != 0 else [0, 0.271]\n",
    "  line = mlines.Line2D(x, [y, y],\n",
    "                        color='black', linestyle='--', linewidth=1,\n",
    "                        transform=fig.transFigure)\n",
    "  fig.add_artist(line)\n",
    "\n",
    "pos = axes[0].get_position()\n",
    "print(pos)\n",
    "print(axes[1].get_position())\n",
    "line = mlines.Line2D([0.271, 0.271], [1, (positions[0].y0 + positions[1].y1) / 2],\n",
    "                     color='black', linestyle='--', linewidth=1,\n",
    "                     transform=fig.transFigure)\n",
    "fig.add_artist(line)\n",
    "plt.show()\n",
    "fig.savefig(\"DS_BER.png\", pad_inches=0.05)\n",
    "fig.savefig(\"DS_BER.pdf\", pad_inches=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = pd.concat(avg_dfs)\n",
    "avg_df.columns\n",
    "\n",
    "# Split into two dataframes\n",
    "df_00 = avg_df[avg_df['Data Pattern'] == '0x00000000'][['module', 'Num. Bitflips']].rename(columns={'Num. Bitflips': 'BER_00'})\n",
    "df_FF = avg_df[avg_df['Data Pattern'] == '0xFFFFFFFF'][['module', 'Num. Bitflips']].rename(columns={'Num. Bitflips': 'BER_FF'})\n",
    "\n",
    "# Merge and calculate normalized values\n",
    "result = df_FF.merge(df_00, on='module')\n",
    "result['normalized_BER'] = result['BER_FF'] / result['BER_00']\n",
    "\n",
    "geometric_mean = np.exp(np.log(result['normalized_BER']).mean())\n",
    "print(geometric_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"./data\"):\n",
    "  for file in files:\n",
    "    if \"rd_rp.csv\" in file and \"mimi\" not in file:\n",
    "      module = file.split(\"_\")[0]\n",
    "      df = pd.read_csv(os.path.join(root, file))\n",
    "      df[\"module\"] = module\n",
    "      dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.loc[df[\"Aggr. Type\"].isin([\"Upper\", \"Lower\"])]\n",
    "modules = data['module'].unique()\n",
    "\n",
    "# Calculate grid dimensions\n",
    "n_cols = 4  # You can adjust this\n",
    "n_rows = (len(modules) + n_cols - 1) // n_cols\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 2*n_rows))\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes\n",
    "\n",
    "\n",
    "avg_dfs = []\n",
    "\n",
    "# Create boxplot for each group\n",
    "for idx, module in enumerate(list(module_mapping.keys())):\n",
    "    # Filter edge victims\n",
    "    ss_data = hcf_df[(hcf_df['module'] == module) & (hcf_df[\"Aggr. Type\"].isin([\"Upper\", \"Lower\"]))]\n",
    "    type_counts = ss_data.groupby('Vic Row')['Aggr. Type'].nunique()\n",
    "    incomplete_idx = type_counts[type_counts == 1].index\n",
    "    incomplete_rows = ss_data[ss_data['Vic Row'].isin(incomplete_idx)][\"Vic Row\"].unique()\n",
    "\n",
    "    group_data = df.loc[(df['module'] == module) & (df[\"Aggr. Type\"].isin([\"Upper\", \"Lower\"]))]\n",
    "    group_data = group_data[~(group_data['Vic Row'].isin(incomplete_rows))]\n",
    "\n",
    "\n",
    "\n",
    "    # Handle Micron true- anti-\n",
    "    if module == \"axmicr02\":\n",
    "      ret_df = pd.read_csv(\"./data/axmicr02_retention.csv\")\n",
    "      ret_df = ret_df.loc[ret_df[\"tWAIT\"] == 4096]\n",
    "\n",
    "      anti_df = ret_df.loc[(ret_df[\"Pattern\"] == \"00000000\") & (ret_df[\"NumBitflips\"] >= 10)]\n",
    "      true_df = ret_df.loc[(ret_df[\"Pattern\"] == \"FFFFFFFF\") & (ret_df[\"NumBitflips\"] >= 10)]\n",
    "\n",
    "      anti_rows = anti_df[\"Row\"].unique() + 1024\n",
    "      true_rows = true_df[\"Row\"].unique() + 1024\n",
    "\n",
    "      group_data = swap_patterns(group_data, list(anti_rows))\n",
    "\n",
    "    adf = group_data.groupby(['Data Pattern', \"Aggr. Type\"])['Num. Bitflips'].mean().reset_index()\n",
    "    adf[\"module\"] = module\n",
    "    avg_dfs.append(adf)\n",
    "\n",
    "\n",
    "    # Create boxplot on the corresponding subplot\n",
    "    group_data = group_data[(group_data['module'] == module)]\n",
    "    if idx == 0:\n",
    "        sns_plot = sns.boxplot(data=group_data, x=\"Data Pattern\", y=\"Num. Bitflips\", \n",
    "                            hue=\"Aggr. Type\", ax=axes[idx], \n",
    "                            order=['0x00000000', '0xFFFFFFFF'], \n",
    "                            palette=['#2185D0', '#DB2828'])\n",
    "        # Get the legend handles and labels from the first plot\n",
    "        handles, labels = axes[0].get_legend_handles_labels()\n",
    "        # Remove the legend from the first plot\n",
    "        axes[0].get_legend().remove()\n",
    "    else:\n",
    "        sns_plot = sns.boxplot(data=group_data, x=\"Data Pattern\", y=\"Num. Bitflips\", \n",
    "                            hue=\"Aggr. Type\", ax=axes[idx], \n",
    "                            order=['0x00000000', '0xFFFFFFFF'], \n",
    "                            palette=['#2185D0', '#DB2828'],\n",
    "                            legend=False)\n",
    "        \n",
    "\n",
    "    mfr = module_mapping[module].split()[1]\n",
    "    if idx not in [0, 1, 8]:\n",
    "      axes[idx].set_title(f'{\" \".join(module_mapping[module].split()[2:])}', weight='bold', color=label_color_map[mfr])\n",
    "    else:\n",
    "      axes[idx].set_title(f'{module_mapping[module]}', weight='bold', color=label_color_map[mfr])\n",
    "    # axes[idx].yaxis.set_major_formatter(FuncFormatter(format_k))\n",
    "    axes[idx].set_xlabel('')\n",
    "    axes[idx].set_ylabel('')\n",
    "    if idx % 4 == 0:\n",
    "       axes[idx].set_ylabel('Num. Bitflips')\n",
    "\n",
    "    y_min, y_max = axes[idx].get_ylim()\n",
    "    margin = (y_max - y_min) * 0.05  # 5% margin\n",
    "    axes[idx].set_ylim(y_min - margin, y_max + margin)\n",
    "    axes[idx].set_yticks(np.linspace(max(y_min - margin, 0), y_max, 5, endpoint=True))\n",
    "\n",
    "\n",
    "    # Make borders thicker\n",
    "    for spine in axes[idx].spines.values():\n",
    "        spine.set_linewidth(1.6)  # Adjust this number to control thickness\n",
    "        spine.set_color('black')\n",
    "    # Get current x-tick labels\n",
    "    current_labels = [label.get_text() for label in axes[idx].get_xticklabels()]\n",
    "    \n",
    "    # Replace labels using the mapping\n",
    "    new_labels = [label_map.get(label, label) for label in current_labels]\n",
    "    \n",
    "    # Set new labels\n",
    "    axes[idx].set_xticklabels(new_labels, weight=\"bold\")\n",
    "\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    axes[idx].yaxis.set_major_locator(MaxNLocator(nbins=6, integer=True))\n",
    "\n",
    "# Remove empty subplots if any\n",
    "for idx in range(len(modules), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "for ax in axes:\n",
    "  ax.grid(True, axis='y', linestyle='--', linewidth=1.0)\n",
    "  ax.tick_params(axis='y', width=1, direction='in', color='black')\n",
    "\n",
    "legend = fig.legend(handles, [label + \" Aggressor\" for label in labels],  # Add 'Type: ' prefix to labels\n",
    "                   bbox_to_anchor=(0.53, 1.00),  # Position legend at top\n",
    "                   loc='lower center',          # Center the legend\n",
    "                   ncol=len(labels),            # Make all items in one row\n",
    "                   frameon=True,                # Add frame\n",
    "                   edgecolor='black',           # Frame color\n",
    "                   prop={'weight': 'bold', 'size': 14})\n",
    "legend.get_frame().set_linewidth(2)\n",
    "\n",
    "plt.tight_layout(h_pad=1.3, w_pad=1.2)\n",
    "import matplotlib.lines as mlines\n",
    "# Retrieve each subplot's position (in figure coordinates)\n",
    "positions = []\n",
    "for i, ax in enumerate(axes):\n",
    "  if i % 4 == 0:\n",
    "     positions.append(ax.get_position())\n",
    "# Loop through consecutive rows to compute and draw the dashed line between them\n",
    "for i in range(len(positions) - 1):\n",
    "  # Compute the y position: average between the bottom of the upper subplot\n",
    "  # and the top of the lower subplot\n",
    "  y = (positions[i].y0 + positions[i+1].y1) / 2\n",
    "  # Create a horizontal dashed line across the figure\n",
    "  x = [0, 1] if i != 0 else [0, 0.273]\n",
    "  line = mlines.Line2D(x, [y, y],\n",
    "                        color='black', linestyle='--', linewidth=1,\n",
    "                        transform=fig.transFigure)\n",
    "  fig.add_artist(line)\n",
    "\n",
    "pos = axes[0].get_position()\n",
    "print(pos)\n",
    "print(axes[1].get_position())\n",
    "line = mlines.Line2D([0.273, 0.273], [1, (positions[0].y0 + positions[1].y1) / 2],\n",
    "                     color='black', linestyle='--', linewidth=1,\n",
    "                     transform=fig.transFigure)\n",
    "fig.add_artist(line)\n",
    "plt.show()\n",
    "fig.savefig(\"DS_RP2.png\", bbox_inches='tight', pad_inches=0.05)\n",
    "fig.savefig(\"DS_RP2.pdf\", bbox_inches='tight', pad_inches=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = pd.concat(avg_dfs)\n",
    "avg_df.columns\n",
    "\n",
    "# Split into two dataframes\n",
    "df_00 = avg_df[(avg_df['Data Pattern'] == '0xFFFFFFFF') & (avg_df['Aggr. Type'] == \"Upper\")][['module', 'Num. Bitflips']].rename(columns={'Num. Bitflips': 'BER_Upper'})\n",
    "df_FF = avg_df[(avg_df['Data Pattern'] == '0xFFFFFFFF') & (avg_df['Aggr. Type'] == \"Lower\")][['module', 'Num. Bitflips']].rename(columns={'Num. Bitflips': 'BER_Lower'})\n",
    "\n",
    "# Merge and calculate normalized values\n",
    "result = df_FF.merge(df_00, on='module')\n",
    "result['normalized_BER'] = result['BER_Upper'] / result['BER_Lower']\n",
    "\n",
    "geometric_mean = np.exp(np.log(result['normalized_BER']).mean())\n",
    "print(geometric_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"./data\"):\n",
    "  for file in files:\n",
    "    if \"ds_ber_sweep.csv\" in file and \"mimi\" not in file and \"nxsasa\" not in file:\n",
    "      module = file.split(\"_\")[0]\n",
    "      df = pd.read_csv(os.path.join(root, file))\n",
    "      df[\"module\"] = module\n",
    "      df = df.drop([\"Temp\", \"Itr\"], axis=1)\n",
    "      dfs.append(df)\n",
    "\n",
    "sweep_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"./data\"):\n",
    "  for file in files:\n",
    "    if \"rd_hcf.csv\" in file and \"mimi\" not in file and \"nxsasa\" not in file:\n",
    "      module = file.split(\"_\")[0]\n",
    "      df = pd.read_csv(os.path.join(root, file))\n",
    "      df[\"module\"] = module\n",
    "      dfs.append(df)\n",
    "\n",
    "hcf_df = pd.concat(dfs)\n",
    "# hcf_df = hcf_df.loc[hcf_df[\"Aggr. Type\"] == \"Double\"]\n",
    "# hcf_df = hcf_df.groupby([\"Vic Row\", \"module\"])[\"HC\"].min().reset_index()\n",
    "\n",
    "hcf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_hcf = []\n",
    "\n",
    "for idx, module in enumerate(list(module_mapping.keys())):\n",
    "    ss_data = hcf_df[(hcf_df['module'] == module) & (hcf_df[\"Aggr. Type\"].isin([\"Upper\", \"Lower\"]))]\n",
    "    type_counts = ss_data.groupby('Vic Row')['Aggr. Type'].nunique()\n",
    "    incomplete_idx = type_counts[type_counts == 1].index\n",
    "    incomplete_rows = ss_data[ss_data['Vic Row'].isin(incomplete_idx)][\"Vic Row\"].unique()\n",
    "\n",
    "    group_data = hcf_df.loc[(hcf_df['module'] == module)]\n",
    "    group_data = group_data[~(group_data['Vic Row'].isin(incomplete_rows))]\n",
    "\n",
    "    # Handle Micron true- anti-\n",
    "    if module == \"axmicr02\":\n",
    "      ret_df = pd.read_csv(\"./data/axmicr02_retention.csv\")\n",
    "      ret_df = ret_df.loc[ret_df[\"tWAIT\"] == 4096]\n",
    "\n",
    "      anti_df = ret_df.loc[(ret_df[\"Pattern\"] == \"00000000\") & (ret_df[\"NumBitflips\"] >= 10)]\n",
    "      true_df = ret_df.loc[(ret_df[\"Pattern\"] == \"FFFFFFFF\") & (ret_df[\"NumBitflips\"] >= 10)]\n",
    "\n",
    "      anti_rows = anti_df[\"Row\"].unique() + 1024\n",
    "      true_rows = true_df[\"Row\"].unique() + 1024\n",
    "\n",
    "      group_data = swap_patterns(group_data, list(anti_rows))\n",
    "\n",
    "    group_data = group_data.loc[(group_data[\"Aggr. Type\"] == \"Double\") & (group_data[\"Data Pattern\"] == \"0x00000000\")]\n",
    "    group_data = group_data.groupby([\"Vic Row\", \"module\"])[\"HC\"].min().reset_index()\n",
    "    processed_hcf.append(group_data)\n",
    "\n",
    "processed_hcf_df = pd.concat(processed_hcf)\n",
    "sdf = pd.merge(processed_hcf_df, sweep_df, on=[\"Vic Row\", \"module\"], how=\"left\", suffixes=('_hcf', '_tp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sdf = sdf.groupby([\"module\"])[[\"HC_hcf\", \"HC_tp\"]].mean().reset_index()\n",
    "out_sdf[\"Normalized\"] = out_sdf[\"HC_tp\"] / out_sdf[\"HC_hcf\"] \n",
    "geometric_mean = np.exp(np.log(out_sdf['Normalized']).mean())\n",
    "print(geometric_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sdf['module'] = pd.Categorical(out_sdf['module'], categories=list(module_mapping.keys()), ordered=True)\n",
    "out_sdf = out_sdf.sort_values('module')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
